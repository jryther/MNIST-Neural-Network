{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 118,282\n",
      "Trainable params: 118,282\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 1.5102 - accuracy: 0.6051 - val_loss: 0.7603 - val_accuracy: 0.8296\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 3s 64us/step - loss: 0.5955 - accuracy: 0.8511 - val_loss: 0.4469 - val_accuracy: 0.8851\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.4300 - accuracy: 0.8843 - val_loss: 0.3666 - val_accuracy: 0.9012\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 61us/step - loss: 0.3702 - accuracy: 0.8971 - val_loss: 0.3301 - val_accuracy: 0.9092\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.3371 - accuracy: 0.9059 - val_loss: 0.3053 - val_accuracy: 0.9156\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.3144 - accuracy: 0.9122 - val_loss: 0.2887 - val_accuracy: 0.9184\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 3s 57us/step - loss: 0.2967 - accuracy: 0.9163 - val_loss: 0.2738 - val_accuracy: 0.9229\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 3s 62us/step - loss: 0.2819 - accuracy: 0.9210 - val_loss: 0.2620 - val_accuracy: 0.9263\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s 52us/step - loss: 0.2696 - accuracy: 0.9243 - val_loss: 0.2513 - val_accuracy: 0.9291\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.2583 - accuracy: 0.9275 - val_loss: 0.2437 - val_accuracy: 0.9303\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.2480 - accuracy: 0.9307 - val_loss: 0.2342 - val_accuracy: 0.9338\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s 56us/step - loss: 0.2383 - accuracy: 0.9324 - val_loss: 0.2268 - val_accuracy: 0.9361\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 3s 52us/step - loss: 0.2296 - accuracy: 0.9359 - val_loss: 0.2228 - val_accuracy: 0.9352\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.2219 - accuracy: 0.9379 - val_loss: 0.2133 - val_accuracy: 0.9392\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.2143 - accuracy: 0.9400 - val_loss: 0.2067 - val_accuracy: 0.9417\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.2075 - accuracy: 0.9413 - val_loss: 0.2009 - val_accuracy: 0.9435\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.2011 - accuracy: 0.9434 - val_loss: 0.1956 - val_accuracy: 0.9459\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.1949 - accuracy: 0.9451 - val_loss: 0.1909 - val_accuracy: 0.9471\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.1892 - accuracy: 0.9463 - val_loss: 0.1866 - val_accuracy: 0.9492\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.1839 - accuracy: 0.9480 - val_loss: 0.1822 - val_accuracy: 0.9487\n",
      "10000/10000 [==============================] - 0s 33us/step\n",
      "Test score: 0.1826389809638262\n",
      "Test accuracy: 0.9478999972343445\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "np.random.seed(1671) # for reproducibility\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# M_HIDDEN hidden layers\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=OPTIMIZER,\n",
    "metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 1.3052 - accuracy: 0.6826 - val_loss: 0.7242 - val_accuracy: 0.8494\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.6205 - accuracy: 0.8516 - val_loss: 0.4933 - val_accuracy: 0.8809\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.4839 - accuracy: 0.8746 - val_loss: 0.4165 - val_accuracy: 0.8916\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.4240 - accuracy: 0.8857 - val_loss: 0.3762 - val_accuracy: 0.8980\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.3884 - accuracy: 0.8939 - val_loss: 0.3500 - val_accuracy: 0.9054\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s 48us/step - loss: 0.3638 - accuracy: 0.8993 - val_loss: 0.3319 - val_accuracy: 0.9086\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.3452 - accuracy: 0.9038 - val_loss: 0.3165 - val_accuracy: 0.9113\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.3301 - accuracy: 0.9082 - val_loss: 0.3050 - val_accuracy: 0.9152\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.3175 - accuracy: 0.9116 - val_loss: 0.2949 - val_accuracy: 0.9180\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s 49us/step - loss: 0.3067 - accuracy: 0.9146 - val_loss: 0.2861 - val_accuracy: 0.9196\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 3s 60us/step - loss: 0.2970 - accuracy: 0.9171 - val_loss: 0.2778 - val_accuracy: 0.9219\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.2880 - accuracy: 0.9197 - val_loss: 0.2708 - val_accuracy: 0.9243\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s 51us/step - loss: 0.2802 - accuracy: 0.9226 - val_loss: 0.2652 - val_accuracy: 0.9257\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s 50us/step - loss: 0.2730 - accuracy: 0.9241 - val_loss: 0.2582 - val_accuracy: 0.9282\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 3s 53us/step - loss: 0.2662 - accuracy: 0.9256 - val_loss: 0.2530 - val_accuracy: 0.9294\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 3s 55us/step - loss: 0.2598 - accuracy: 0.9275 - val_loss: 0.2475 - val_accuracy: 0.9321\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 3s 54us/step - loss: 0.2540 - accuracy: 0.9293 - val_loss: 0.2427 - val_accuracy: 0.9330\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 3s 67us/step - loss: 0.2485 - accuracy: 0.9305 - val_loss: 0.2384 - val_accuracy: 0.9332\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 3s 63us/step - loss: 0.2432 - accuracy: 0.9321 - val_loss: 0.2339 - val_accuracy: 0.9357\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 3s 68us/step - loss: 0.2384 - accuracy: 0.9337 - val_loss: 0.2299 - val_accuracy: 0.9362\n",
      "10000/10000 [==============================] - 0s 37us/step\n",
      "Test score: 0.23213751326203347\n",
      "Test accuracy: 0.9355999827384949\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1671) # for reproducibility\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# M_HIDDEN hidden layers\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=OPTIMIZER,\n",
    "metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 10)                1290      \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 151,306\n",
      "Trainable params: 151,306\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 1.6967 - accuracy: 0.5331 - val_loss: 0.7662 - val_accuracy: 0.8176\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.5615 - accuracy: 0.8442 - val_loss: 0.4161 - val_accuracy: 0.8802\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.3980 - accuracy: 0.8864 - val_loss: 0.3383 - val_accuracy: 0.9038\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.3378 - accuracy: 0.9039 - val_loss: 0.3013 - val_accuracy: 0.9131\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 4s 85us/step - loss: 0.3004 - accuracy: 0.9138 - val_loss: 0.2719 - val_accuracy: 0.9227\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 4s 91us/step - loss: 0.2736 - accuracy: 0.9208 - val_loss: 0.2514 - val_accuracy: 0.9282\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.2514 - accuracy: 0.9280 - val_loss: 0.2377 - val_accuracy: 0.9323\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.2330 - accuracy: 0.9329 - val_loss: 0.2230 - val_accuracy: 0.9351\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 4s 90us/step - loss: 0.2176 - accuracy: 0.9369 - val_loss: 0.2074 - val_accuracy: 0.9422\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 5s 95us/step - loss: 0.2045 - accuracy: 0.9411 - val_loss: 0.1994 - val_accuracy: 0.9423\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 5s 98us/step - loss: 0.1932 - accuracy: 0.9441 - val_loss: 0.1882 - val_accuracy: 0.9473\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.1831 - accuracy: 0.9465 - val_loss: 0.1823 - val_accuracy: 0.9479\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 4s 86us/step - loss: 0.1744 - accuracy: 0.9488 - val_loss: 0.1737 - val_accuracy: 0.9511\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1654 - accuracy: 0.9521 - val_loss: 0.1705 - val_accuracy: 0.9513\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1580 - accuracy: 0.9539 - val_loss: 0.1663 - val_accuracy: 0.9523\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1511 - accuracy: 0.9557 - val_loss: 0.1600 - val_accuracy: 0.9551\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 4s 93us/step - loss: 0.1443 - accuracy: 0.9581 - val_loss: 0.1552 - val_accuracy: 0.9570\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 4s 88us/step - loss: 0.1387 - accuracy: 0.9596 - val_loss: 0.1479 - val_accuracy: 0.9582\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 4s 89us/step - loss: 0.1332 - accuracy: 0.9607 - val_loss: 0.1481 - val_accuracy: 0.9580\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 4s 87us/step - loss: 0.1279 - accuracy: 0.9630 - val_loss: 0.1419 - val_accuracy: 0.9593\n",
      "10000/10000 [==============================] - 0s 43us/step\n",
      "Test score: 0.1404169532723725\n",
      "Test accuracy: 0.9577999711036682\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1671) # for reproducibility\n",
    "# network and training\n",
    "NB_EPOCH = 20\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10 # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # optimizer, explained later in this chapter\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT=0.2 # how much TRAIN is reserved for VALIDATION\n",
    "# data: shuffled and split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "# normalize\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "# M_HIDDEN hidden layers\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "model = Sequential()\n",
    "model.add(Dense(N_HIDDEN, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(N_HIDDEN))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(NB_CLASSES))\n",
    "model.add(Activation('softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "optimizer=OPTIMIZER,\n",
    "metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"Test score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning the training data set is labeled data used to teach the model how to fit the weights and bias of the neural web.  The validation set is used to tune hyperparameters.  Hyperparameters are values that  control the learning process such as learning rate and batch-size.  This test becomes more biased over time as the validation data set is incorporated into the model configuration.  Last is the test data set which is used to provide an unbiased evaluation of the model after it has fully completed training.  In most cases, as parameters are increased for each test the computational demand also increases.  That is why it is important to find a balance between parameters that are accurate but also do not take too much time or resources.  By increasing the number of hidden layers this will improve the accuracy of the training set but can cause over-fitting if over done which decreases accuracy for the model test.  In steps 3 and 4 of the assignment I tried adjusting the number of hidden numbers to 1 and 4 respectively.  The baseline of 2 layers produced a test accuracy of 94.79%, with 1 layer as 93.56%, and 4 layers as 95.78%.  Training and validation accuracy also followed the same trend by decreasing with less layers and increasing with more.  This can be attested to a better proportion of parameters for the model since there is a relation between the right mix of hyperparameters.\n",
    "\n",
    "**Resources:**\n",
    "\n",
    "1. Gulli, A., & Pal, S. (2017). Deep learning with keras. Packt Publishing, Limited.\n",
    "\n",
    "2. Brownlee, J. (2017, July 14). What is the difference between test and validation datasets? Machine Learning Mastery. Retrieved October 30, 2021, from https://machinelearningmastery.com/difference-test-validation-datasets/.\n",
    "\n",
    "3. Wikimedia Foundation. (n.d.). Training, validation, and test sets. Wikipedia. Retrieved October 30, 2021, from https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets.\n",
    "\n",
    "4. Wikimedia Foundation. (n.d.). Hyperparameter (machine learning). Wikipedia. Retrieved October 30, 2021, from https://en.wikipedia.org/wiki/Hyperparameter_(machine_learning). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
